{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cv2 import aruco\n",
    "import numpy as np\n",
    "import msgpack as mp\n",
    "import msgpack_numpy as mpn\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_webcam_calib_video = r\"D:\\CMC\\pyprojects\\visual-vibe\\calibration\\webcam_color.msgpack\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARUCO_PARAMETERS = aruco.DetectorParameters()\n",
    "ARUCO_DICT = aruco.getPredefinedDictionary(aruco.DICT_ARUCO_ORIGINAL)\n",
    "detector = aruco.ArucoDetector(ARUCO_DICT, ARUCO_PARAMETERS)\n",
    "markerLength = 0.05\n",
    "markerSeperation = 0.01\n",
    "\n",
    "board = aruco.GridBoard(\n",
    "        size= [1,1],\n",
    "        markerLength=markerLength,\n",
    "        markerSeparation=markerSeperation,\n",
    "        dictionary=ARUCO_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_video_pth = _webcam_calib_video\n",
    "_video_file = open(_video_pth, \"rb\")\n",
    "_video_data = mp.Unpacker(_video_file, object_hook=mpn.decode)\n",
    "_video_length = 0\n",
    "\n",
    "for _frame in _video_data:\n",
    "    corners, ids, rejected_image_points = detector.detectMarkers(_frame)\n",
    "    if ids is not None:\n",
    "\n",
    "        _video_length += 1\n",
    "\n",
    "_video_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_video_pth = _webcam_calib_video\n",
    "_video_file = open(_video_pth, \"rb\")\n",
    "_video_data = mp.Unpacker(_video_file, object_hook=mpn.decode)\n",
    "\n",
    "marker_corners = []\n",
    "object_points = []\n",
    "first = True\n",
    "counter = []\n",
    "for idx, _frame in enumerate(_video_data):\n",
    "    \n",
    "    _frame = cv2.cvtColor(_frame, cv2.COLOR_BGR2GRAY)\n",
    "    corners, ids, rejected_image_points = detector.detectMarkers(_frame)\n",
    "    if ids is not None:\n",
    "        if first == True:\n",
    "            corners_list = corners\n",
    "            id_list = ids\n",
    "            first = False\n",
    "        else:\n",
    "            corners_list = np.vstack((corners_list, corners))\n",
    "            id_list = np.vstack((id_list,ids))\n",
    "        counter.append(len(ids))\n",
    "\n",
    "_video_file.close()\n",
    "\n",
    "counter = np.array(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd = np.random.choice(_video_length, 150, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,   5,   6,  14,  16,  17,  20,  23,  26,  31,  55,  56,  58,\n",
       "        59,  60,  68,  70,  83,  86,  95, 101, 105, 106, 113, 114, 118,\n",
       "       121, 128, 135, 141, 147, 155, 167, 177, 179, 185, 187, 196, 199,\n",
       "       205, 209, 219, 223, 228, 240, 242, 243, 248, 255, 259, 261, 270,\n",
       "       277, 279, 280, 291, 292, 299, 301, 302, 309, 311, 313, 314, 319,\n",
       "       322, 323, 325, 334, 342, 352, 354, 360, 371, 372, 374, 376, 381,\n",
       "       390, 393, 399, 402, 404, 408, 409, 418, 422, 429, 434, 450, 452,\n",
       "       460, 463, 466, 482, 483, 485, 490, 491, 508, 509, 513, 516, 521,\n",
       "       526, 532, 541, 547, 562, 570, 572, 580, 581, 587, 594, 602, 607,\n",
       "       618, 626, 635, 637, 639, 642, 645, 649, 650, 652, 655, 658, 663,\n",
       "       673, 677, 680, 685, 693, 695, 696, 701, 702, 705, 721, 752, 754,\n",
       "       756, 757, 758, 760, 770, 771, 772])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd.sort()\n",
    "rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.ones(len(corners_list), dtype=bool)\n",
    "current_index = 0\n",
    "previous_index = 0\n",
    "for idx, vals in enumerate(counter):\n",
    "    previous_index = current_index\n",
    "    current_index += vals\n",
    "    if idx not in rnd:\n",
    "        arr[previous_index:current_index] = False\n",
    "\n",
    "selected_corners = corners_list[arr, ...]\n",
    "selected_ids = id_list[arr, ...]\n",
    "selected_counter = counter[rnd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,   5,   6,  14,  16,  17,  20,  23,  26,  31,  55,  56,  58,\n",
       "        59,  60,  68,  70,  83,  86,  95, 101, 105, 106, 113, 114, 118,\n",
       "       121, 128, 135, 141, 147, 155, 167, 177, 179, 185, 187, 196, 199,\n",
       "       205, 209, 219, 223, 228, 240, 242, 243, 248, 255, 259, 261, 270,\n",
       "       277, 279, 280, 291, 292, 299, 301, 302, 309, 311, 313, 314, 319,\n",
       "       322, 323, 325, 334, 342, 352, 354, 360, 371, 372, 374, 376, 381,\n",
       "       390, 393, 399, 402, 404, 408, 409, 418, 422, 429, 434, 450, 452,\n",
       "       460, 463, 466, 482, 483, 485, 490, 491, 508, 509, 513, 516, 521,\n",
       "       526, 532, 541, 547, 562, 570, 572, 580, 581, 587, 594, 602, 607,\n",
       "       618, 626, 635, 637, 639, 642, 645, 649, 650, 652, 655, 658, 663,\n",
       "       673, 677, 680, 685, 693, 695, 696, 701, 702, 705, 721, 752, 754,\n",
       "       756, 757, 758, 760, 770, 771, 772])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd.sort()\n",
    "rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_flags = cv2.CALIB_USE_LU\n",
    "term_criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtx2 = np.zeros((3, 3))\n",
    "dist2 = np.zeros((1, 8))\n",
    "rvec2 = [np.zeros((1, 1, 3), dtype=np.float64) for i in range(len(counter))]\n",
    "tvec2 = [np.zeros((1, 1, 3), dtype=np.float64) for i in range(len(counter))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ret1, mtx1, dist1, rvecs1, tvecs1 = aruco.calibrateCameraAruco(corners_list, id_list, counter, board, _frame.shape[:2], mtx2, dist2, flags=calibration_flags, criteria = term_criteria)\n",
    "ret1, mtx1, dist1, rvecs1, tvecs1 = aruco.calibrateCameraAruco(selected_corners, selected_ids, selected_counter, board, _frame.shape[:2], mtx2, dist2, flags=calibration_flags, criteria = term_criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import toml\n",
    "_toml_pth = r\"D:\\CMC\\pyprojects\\visual-vibe\\calibration\\camera_calibration.toml\"\n",
    "\n",
    "data = toml.load(_toml_pth)\n",
    "data['calibration']['camera_matrix'] = mtx1.tolist()\n",
    "data['calibration']['dist_coeffs'] = dist1.tolist()\n",
    "with open(_toml_pth, 'w') as f:\n",
    "    toml.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.55197429e+03, 0.00000000e+00, 3.85140807e+02],\n",
       "       [0.00000000e+00, 1.96280120e+03, 6.19299916e+02],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtx1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
